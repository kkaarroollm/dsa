### Sorting Algorithms ‚Äì Study Notes

#### üìå General idea of Sorting:

Sorting algorithms rearrange elements into ascending (or descending) order. Efficiency and optimal use depend on the input size and structure.

---

### 1Ô∏è‚É£ Selection Sort

* **How it works:**

  * Repeatedly find the smallest (or largest) element from the unsorted part and put it at the beginning.

* **Complexity:**

  * Best, Average, Worst-case: **O(n¬≤)**

* **Performance:**

  * Input doesn't significantly affect performance; always quadratic.
  * Good for small arrays; poor performance on large datasets.

* **Linked Lists:**

  * Inefficient (frequent traversal needed).

* **Stability:**

  * Not stable (can change order of identical elements).

---

### 2Ô∏è‚É£ Insertion Sort

* **How it works:**

  * Builds sorted array incrementally, inserting each element into its correct position.

* **Complexity:**

  * Best-case: **O(n)** (already sorted)
  * Average/Worst-case: **O(n¬≤)**

* **Performance:**

  * Excellent for nearly-sorted or small datasets.
  * Slow for large, randomly ordered datasets.

* **Linked Lists:**

  * Efficient (constant insertion time).

* **Stability:**

  * Stable (preserves order of identical elements).

---

### 3Ô∏è‚É£ Merge Sort

* **How it works:**

  * Divide and conquer: split list into halves, recursively sort, then merge sorted halves.

* **Complexity:**

  * Best, Average, Worst-case: **O(n log n)**

* **Merge Function:**

  * Key part: efficiently combines sorted sequences.

* **Performance:**

  * Consistently efficient for all inputs.

* **Linked Lists:**

  * Very efficient (ideal for lists due to easy merging).

* **Stability:**

  * Stable (order of identical elements preserved).

---

### 4Ô∏è‚É£ Quicksort

* **How it works:**

  * Select pivot, partition array around pivot, recursively sort partitions.

* **Complexity:**

  * Best/Average-case: **O(n log n)**
  * Worst-case: **O(n¬≤)** (poor pivot choice)

* **Partition Function:**

  * Critical step: rearranging around the pivot.

* **Performance:**

  * Fastest for typical random data.
  * Slowest for sorted or reverse-sorted data (bad pivot choices).

* **Linked Lists:**

  * Inefficient due to partitioning.

* **Stability:**

  * Not stable (partitioning can rearrange identical elements).

---

### 5Ô∏è‚É£ Counting Sort

* **How it works:**

  * Counts occurrences of each value; calculates positions based on cumulative count.

* **Complexity:**

  * Best, Average, Worst-case: **O(n + k)**, k - range of input values

* **Performance:**

  * Optimal when range (k) isn't significantly greater than n.

* **Linked Lists:**

  * Generally impractical due to the counting step.

* **Stability:**

  * Stable if implemented carefully (counts positionally).

---

### 6Ô∏è‚É£ Radix Sort

* **How it works:**

  * Sorts numbers digit-by-digit, from least significant to most significant.

* **Complexity:**

  * Best, Average, Worst-case: \**O(d*(n + k))\*\*, d - number of digits, k - digit range

* **Performance:**

  * Excellent for sorting integers, strings, fixed-length data.

* **Linked Lists:**

  * Can be implemented effectively with linked lists.

* **Stability:**

  * Stable (preserves order across digit-based sorting).

---

### üìå Algorithm Comparison:

| Algorithm      | Avg. Complexity | Best Data                 | Worst Data            | Stability | Linked List Efficiency |
| -------------- | --------------- | ------------------------- | --------------------- | --------- | ---------------------- |
| Selection Sort | O(n¬≤)           | Small arrays              | Large arrays          | ‚ùå         | Poor                   |
| Insertion Sort | O(n¬≤)           | Nearly sorted             | Reverse/random        | ‚úÖ         | Good                   |
| Merge Sort     | O(n log n)      | General-purpose sorting   | Always efficient      | ‚úÖ         | Excellent              |
| Quicksort      | O(n log n)      | Random data               | Sorted/reverse sorted | ‚ùå         | Poor                   |
| Counting Sort  | O(n + k)        | Small range of values     | Large range           | ‚úÖ         | Poor                   |
| Radix Sort     | O(d\*(n + k))   | Fixed-length numeric data | Large range of digits | ‚úÖ         | Good                   |

---

### üìå Stability:

* **Stable algorithms:** Insertion, Merge, Counting (carefully implemented), Radix
* **Not Stable:** Selection, Quicksort

**Why stability matters:**

* Important when sorting by multiple criteria (e.g., first by name, then by age).

---

### üìå Mathematical Lower Limit for Sorting by Comparisons:

* No comparison-based sorting algorithm can do better than **O(n log n)** in the worst-case.
* Derived using decision-tree argument: sorting n elements requires log(n!) comparisons ‚âà **n log n**.


---

Sorting Algorithms Comprehensive Notes

1. Algorithm Overviews:
	‚Ä¢	Selection Sort:
	‚Ä¢	Complexity: O(n¬≤) always
	‚Ä¢	Idea: Select smallest/largest element and move to correct position.
	‚Ä¢	Stability: Unstable (swaps non-adjacent elements)
	‚Ä¢	Suitable for small data sets, not efficient on large ones.
	‚Ä¢	Performs poorly on large lists; consistent but slow.
	‚Ä¢	Insertion Sort:
	‚Ä¢	Complexity: O(n¬≤) average/worst; O(n) best-case (sorted list)
	‚Ä¢	Idea: Insert element into the correct sorted position.
	‚Ä¢	Stability: Stable (only moves elements to right)
	‚Ä¢	Efficient on small or nearly sorted data sets.
	‚Ä¢	Good performance with linked lists (easy insertion).
	‚Ä¢	Merge Sort:
	‚Ä¢	Complexity: O(n log n) always
	‚Ä¢	Idea: Divide, recursively sort, merge sorted halves.
	‚Ä¢	Stability: Stable (maintains order during merging)
	‚Ä¢	Suitable for large data sets.
	‚Ä¢	Excellent with linked lists (no random access needed).
	‚Ä¢	QuickSort:
	‚Ä¢	Complexity: Average O(n log n), Worst-case O(n¬≤)
	‚Ä¢	Idea: Partition around pivot; recursively sort partitions.
	‚Ä¢	Stability: Unstable (partition swaps elements unpredictably)
	‚Ä¢	Efficient for large, random data; poor with already sorted or reverse-sorted data.
	‚Ä¢	Poor performance with linked lists (partitioning difficult).
	‚Ä¢	Counting Sort:
	‚Ä¢	Complexity: O(n + k) (k = range of input)
	‚Ä¢	Idea: Count occurrences; cumulative sums; reorder accordingly.
	‚Ä¢	Stability: Stable (preserves original relative order)
	‚Ä¢	Efficient when data range (k) is not significantly larger than input size (n).
	‚Ä¢	Only integers or discrete values; ineffective if range is large.
	‚Ä¢	Radix Sort:
	‚Ä¢	Complexity: O(nk) (k = number of digits/characters in max element)
	‚Ä¢	Idea: Sort elements digit by digit from least significant to most significant.
	‚Ä¢	Stability: Stable (maintains original relative order)
	‚Ä¢	Efficient with fixed-length numbers/strings.
	‚Ä¢	Best for data with uniform length.

‚∏ª

2. Pairwise Comparison:
	‚Ä¢	Selection vs. Insertion:
	‚Ä¢	Insertion better with nearly sorted/small data; selection always quadratic.
	‚Ä¢	Selection vs. Merge:
	‚Ä¢	Merge better for larger datasets (O(n log n)); selection slower.
	‚Ä¢	Selection vs. QuickSort:
	‚Ä¢	QuickSort usually faster, except worst-case; selection always slow.
	‚Ä¢	Insertion vs. Merge:
	‚Ä¢	Merge for large datasets; insertion quicker for small or nearly sorted data.
	‚Ä¢	Insertion vs. QuickSort:
	‚Ä¢	QuickSort faster on average; insertion better for nearly sorted/small.
	‚Ä¢	Merge vs. QuickSort:
	‚Ä¢	Merge guarantees O(n log n); QuickSort often faster practically but O(n¬≤) worst-case.
	‚Ä¢	Counting vs. Radix:
	‚Ä¢	Counting ideal for small range; Radix handles larger numeric ranges better.
	‚Ä¢	Counting/Radix vs. Comparison-based:
	‚Ä¢	Counting/Radix faster for integers within limited ranges, otherwise impractical.

‚∏ª

3. Stability:
	‚Ä¢	Stable Algorithms:
	‚Ä¢	Insertion Sort, Merge Sort, Counting Sort, Radix Sort
	‚Ä¢	Unstable Algorithms:
	‚Ä¢	Selection Sort, QuickSort

Stability is important when sorting records based on multiple criteria.

‚∏ª

4. Linked List Performance:
	‚Ä¢	Good: Insertion Sort, Merge Sort (excellent for linked lists)
	‚Ä¢	Poor: QuickSort, Selection Sort, Counting and Radix (require random access)

‚∏ª

5. Mathematical Lower Limit for Comparison-Based Sorting:
	‚Ä¢	Theoretical limit: O(n log n)
	‚Ä¢	Proven by decision-tree model for comparison-based sorting algorithms
	‚Ä¢	Algorithms like Merge Sort or Heap Sort meet this bound.
	‚Ä¢	Non-comparison-based sorts (Counting, Radix) can surpass this limit.
